#Q.What is Docker? Why we need docker?
A. Docker is a containerization platform that allows developers to package, ship, and run applications in
containers. Containers are lightweight and portable, making it easier to develop, test, and deploy applications.

#Q.What are containers?
A. Containers are a type of virtualization that allows multiple applications to run on a single host operating
system, each with its own isolated environment. Containers share the host operating system, but each container
has its own file system, network stack, and process space.

#Q.Difference between container and image?
A.          Image                                container
 1. A static, executable package             1. A running instance of an image.
    containing everything needed
    to run software.
 2. Immutable (does not change               2. Mutable (can be modified).
    once created).
 3. Serves as a blueprint or                 3. Provides an isolated environment for running applications.
    template for creating containers.
 4. No isolation; just a file system         4. Isolated from other containers and the host system.
    snapshot.
 5. Built using a Dockerfile with a          5. Created from an image using the docker run command.gi
    set of instructions.

#Q.What is the difference between docker and virtual machine?

| Feature            | **Docker (Containers)**                 | **Virtual Machines (VMs)**       |
| ------------------ | --------------------------------------- | -------------------------------- |
| **OS Sharing**     | Shares **host OS kernel**               | Has its **own guest OS**         |
| **Boot Time**      | **Seconds**                             | **Minutes**                      |
| **Size**           | **MBs**                                 | **GBs**                          |
| **Isolation**      | Process-level (via namespaces, cgroups) | Hardware-level (via hypervisor)  |
| **Resource Usage** | **Lightweight**                         | **Heavy**                        |
| **Portability**    | Very high                               | Moderate                         |
| **Use Case**       | Microservices, CI/CD pipelines          | Monolithic apps, full OS testing |


#Q. What are the different types of docker containers?
A. 1. Stateless Containers
 Stateless containers are containers that do not store any data or state. They are typically used for web 
 servers, load balancers, and other applications that do not require persistent data.
 eg:- docker run -d -p 80:80 nginx

 2. Stateful Containers
 Stateful containers are containers that store data or state. They are typically used for databases, 
 file servers, and other applications that require persistent data. 
 eg:- docker run -d -p 5432:5432 -v /var/lib/postgresql/data:/var/lib/postgresql/data postgres

 3. Init Containers
 Init containers are containers that run before the main container and perform initialization tasks.
 They are typically used for setting up the environment, creating directories, and other initialization tasks.
 eg:- docker run -d --name my-init --init my-init-image
      docker run -d --name my-app --depends-on my-init my-app-image

 4. Ephemeral Containers
 Ephemeral containers are containers that are created and deleted on the fly. They are typically used for 
 testing, debugging, and other short-lived tasks.

 5. Daemon Containers
 Daemon containers are containers that run in the background and perform tasks without user interaction. 
 They are typically used for system services, such as logging, monitoring, and backup.

 6. Sidecar Containers
 Sidecar containers are containers that run alongside other containers and provide additional functionality.
 They are typically used for logging, monitoring, and other tasks.
 eg:- docker run -d --name my-app -p 80:80 my-app-image
      docker run -d --name my-sidecar --link my-app my-sidecar-image



#install docker in linux.

enable & start docker
sudo systemctl enable docker
sudo systemctl start docker
sudo ststemctl status docker
sudo docker run -d -p instance-port:container port container name or container ID (-d for detached -p for port forwarding -P for random port forwording)
sudo docker images
sudo docker ps -a --> to see all stopped containers
sudo docker ps
sudo docker run -itd amazonlinux bash
sudo docker exec -it <container_id> /bin/bash --> to go inside the docker shell
cd usr/share/nginx.html/
rm index.html
echo "hello world" > index.html
sudo docker inspect <container_id> --> to inspect docker container 
sudo docker logs <container_id> --> to get logs of the container
sudo docker stop <container_id> --> to stop the container
sudo docker start <container_id> --> to start the container
sudo docker rm <container_id> --> to remove the container
sudo docker rmi <image_id> --> to remove the image
sudo docker rmi -f <image_id> --> to remove the image forcefully
sudo docker commit <container_id> --> to create a image after making changes in the container
sudo docker image --> to see all images for docker
sudo docker tag <image_id> <new_image_name> --> to tag the image

#login into the docker account in linux

sudo docker login --> to login into the docker
sudo docker push <docker provided name> -->
sudo docker run --name <> -d -P <name of repo>
sudo docker tag demo (username)/(reponame)
sudo docker push (username)/(reponame):latest

#if I want to create my private image you can use ECR

you have to create a ec2 role for ecr <ec2containerregistryfullaccess>
copy login command
aws ecr get-login-password --region <region> --profile <profile> | docker login --username AWS 
sudo docker tag <image_id> <account_id>.dkr.ecr.<region>.amazonaws
sudo docker push <account_id>.dkr.ecr.<region>.amazonaws/<image_name>
sudo docker pull <account_id>.dkr.ecr.<region>.amazonaws/<image_name>

# What is the difference between docker stop and docker kill?

| Command         | `docker stop`                                       | `docker kill`                                |
| --------------- | --------------------------------------------------- | -------------------------------------------- |
| **Signal Sent** | Sends `SIGTERM` first, then `SIGKILL` after timeout | Sends `SIGKILL` immediately                  |
| **Graceful?**   | Yes – allows the container to shut down cleanly     | No – forcefully terminates the container     |
| **Use Case**    | When you want to give the app time to clean up      | When a container is **hung or unresponsive** |
| **Timeout**     | Waits 10 seconds (default) before force-killing     | No wait – kills instantly                    |


etc/docker
# docker volumes:-
  This is bind Mount:
- docker run -d -v host_dir_path/:/container_dir_path -p 8080:8080 image_name:latest --> to connect a folder from host server to a folder in container to persist 
 the data i.e. if we delete the container the connected folder data will still be present in the host machine.(does not work in a local set-up)
 
 This is named volume:
- docker run -d -v volume_name:/container_dir_path -p 8080:8080 image_name:latest --> to connect a named volume to a folder in container to persist the data i.e. 
  if we delete the container the connected volume data will still be present in the host machine.

- docker volume create volume_name  --> to create docker volume (universal docker storage)
- docker volume ls                  --> to list volumes
- docker volume inspect demo-volume --> to inspect the volume
- docker volume rm volume_name      --> to remove the volume
- /var/lib/docker/volumes           --> root directory of docker volumes
- cd var/lib/docker                 --> root directory of docker
- /var/run/docker.sock              --> docker socket file

# Q.what is socket file?
# A.socket file is a file that allows two processes to communicate with each other.

sudo docker run -d -v dev:usr/share/nginx/html -P nginx --> to add volume to the container
sudo -v for volume dev for volume name :path to mount volume --name --> for adding name to container

## DOCKERFILE:-

 # dockerfile is a text file that contains instructions for building a docker image.
 # docker file is a step by step instruction to our docker image.

 # dockerfile commands:-

   1. FROM:- it is used to specify the base image for our image.
   2. RUN:- it is used to run a command in the container.
   3. COPY:- it is used to copy a file from the local machine to the container.
   4. ADD:- it is used to copy a file from the local machine to the container.
   5. WORKDIR:- it is used to set the working directory in the container.
   6. EXPOSE:- it is used to specify the port that the container will listen on.
   7. ENV:- it is used to set an environment variable in the container.
   8. VOLUME:- it is used to specify a directory in the container that will be persisted ev
   9. CMD:- it is used to specify the default command to run when the container is started.
   10. ENTRYPOINT:- it is used to specify the default command to run when the container is started
   11. USER:- it is used to specify the user that the container will run as.
   12. ONBUILD:- it is used to specify a command that will be run when the image is
   13. ARG:- it is used to specify a variable that can be passed to the dockerfile.
   14. LABEL:- it is used to specify a label that can be used to identify the image.

   >>> demofile: (to create a dockerfile that runs free css template in nginx but the mentioned css template should be where the docker file is present)
   FROM nginx
   COPY mediplus-lite /usr/share/nginx/html/

   vim dockerfile --> paste above to dockerfile
   dockerfile command --> "docker build -t dockerfile ."


## MultiStage docker file
- multi-stage docker file is a feature of docker that allows you to build a docker image in multiple stages.
- Each stage is a separate docker image, and you can use the output of one stage as the input for the next.
- After completing the first stage and going on the second stage 'docker will remove' the previous stages image.

##task1 using multistage dockerfile
 tomcat alpine --> lightest tomcat image

 Here we do not need to EXPOSE as tomcat we are using tomcat directly.

 FROM 3.9.9-amazoncorretto-8-debian-bookworm AS mvnbuilder # we gave the maven repo mvnbuilder name using AS
 COPY student-ui /. # copied the studnet-ui from local to maven container
 RUN mvn clean package # run the maven command to build the student-ui

 FROM tomcat:jre8-alpine
 COPY --from=mvnbuilder /target/*.war webapps/student.war # copied the war file from maven container to tomcat container using "from=(container_name)"

# How do you reduce image size?
✅ 1. Use a Minimal Base Image
Prefer lightweight images like:
alpine (~5MB)
scratch (empty image, advanced use)

✅ 2. Use Multi-Stage Builds
Split the build and runtime steps into multiple stages.
Only copy the final binaries/files to the last (small) image.

✅ 3. Combine RUN Instructions
Combine commands into a single RUN layer to avoid creating multiple image layers.
Example:

RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

✅ 4. Clean Up Temporary Files
Delete unnecessary files after install (e.g., apt cache, build tools).
Example:
RUN apt-get update && \
    apt-get install -y build-essential && \
    make build && \
    apt-get purge -y build-essential && \
    rm -rf /var/lib/apt/lists/*

✅ 5. Avoid Installing Unused Packages
Only install the exact dependencies needed.
Avoid apt-get install -y build-essential unless really required.

✅ 6. Use .dockerignore File
Prevent copying unnecessary files like .git, node_modules, test files.
Sample .dockerignore:
nginx
node_modules
*.log
.git
Dockerfile

✅ 7. Use Language-Specific Slim Tools
Use slimmed base images:
python:3.11-slim
node:18-alpine
Or use tools like:
docker-slim – Automatically minifies images.

✅ 8. Avoid Installing via curl | bash (if avoidable)
These scripts may add unnecessary tools or files. Use package managers or manual install when possible.

✅ 9. Use Specific Copying Instead of Whole Folders
Instead of COPY . ., copy only what’s needed:
COPY package.json .
COPY src/ ./src/

✅ 10. Use Static Binaries (if possible)
Build and copy static binaries only (e.g., in Go, Rust), then use scratch or alpine as final image.

 #Q. Why docker use 172.16.0.0/16 ip range?
 A. Docker uses 172.16.0.0/16 ip range because it is a private ip range that is not routable on the internet.
 It is used to prevent conflicts with the host machine's ip address and to provide a unique ip address for each container.

## Docker Compose
- Docker compose is a tool for defining and running multi-container docker applications. 
- It allows you to define the services, networks, and volumes for your application in a single file called docker-compose.yml.

 # steps to install docker compose
 sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
 sudo chmod +x /usr/local/bin/docker-compose

 sudo docker file name --> docker-compose.yml
 sudo docker compose up --> to start the containers
 sudo docker compose up -d --> to start the containers in detached mode i.e. in background
 sudo docker compose down --> to stop the containers
 
 # demo docker compose file
 docker compose filename --> docker-compose.yaml
 services:
  tomcat:
    image: prathameshbhujade/tomcat_student-ui
    ports:
      - "8080:8080"

   nginx_app:
    image: nginx:latest
    ports:
    - "80:80"

# How do you scale services using Docker Compose?
- To scale services using Docker Compose, you use the --scale flag with docker-compose up.
- docker-compose up --scale <service_name>=<number_of_instances>
- Example:
  docker-compose up --scale web=3
  This runs 3 instances of the web service.
- Useful for load balancing, testing, or simulating a multi-instance setup.

# .dockerignore file -->
- The .dockerignore file tells Docker which files and directories to exclude from the build context when running docker build.
- Why It’s Important to Add It:
 1. Faster Builds
   Excluding unnecessary files (e.g., node_modules, .git, logs) reduces the size of the build context sent to the Docker daemon.
 2. Smaller Images
   Prevents accidentally copying unwanted files into the image, keeping it lean.
 3. Better Security
   Helps avoid leaking secrets or environment files (e.g., .env, id_rsa, etc.).
 4. Prevents Cache Busting
   Unnecessary file changes (like log files) won’t trigger Docker cache invalidation when excluded.